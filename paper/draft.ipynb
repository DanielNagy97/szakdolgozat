{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Optical Flow-based Symbol Recognition Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">TODO: Megnézni más címeket is példának!</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Journal: http://scientificbulletin.upm.ro/?pag=submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keywords**: Human Computer Interaction, Augmented Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abstract**: Symbol recognizer instead of a full OCR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The research of the proper human-computer interaction is one of the fundamental problems of computer science.\n",
    "The motivation behind them is to find the most natural way of the communication with the help of machines.\n",
    "The increasing number of Augmented Reality and Virtual Reality applications signs the relevance and actuality of the presented topic.\n",
    "\n",
    "The goal of this paper is to provide an alternative method for solving the symbol recognition problem where the input is a video stream.\n",
    "In the considered scenario the user draws various symbols into the air in front of the camera.\n",
    "There is a set of predefined symbols.\n",
    "We have to provide an image processing method and a classification algorithm which can guess the symbol with sufficient accuracy.\n",
    "\n",
    "The proposed symbol recognition method uses motion flow information for estimating the recently drawn symbols.\n",
    "Compared to the classical object tracking methods it has the following advantages and disadvantages.\n",
    "\n",
    "The main benefit of this approach is the shape and texture invariance.\n",
    "Most of the available methods combines shape detection and object tracking techniques [].\n",
    "Therefore, the reliability of the symbol recognition depends on the accuracy of these two different steps.\n",
    "\n",
    "An object detection and a pose estimation method can provide detailed information about the tracked object.\n",
    "In our use case these informations are ignored.\n",
    "It means that, our system is unable to differentiate between a human hand and an arbitrary pointer device on the images.\n",
    "\n",
    "[DTW-s cikk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video stream processing method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processing of the video stream is a multistep process.\n",
    "The video stream is the sequence of coloured images.\n",
    "We call these images as frames.\n",
    "The format and the resolution of all frames are the same.\n",
    "The elapsed time between two sequential frames can be considered as a constant value, denoted by $\\Delta t$.\n",
    "Let see the overview of the proposed method in Figure [].\n",
    "We describe the details of the processing steps in the following subsections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">TODO: Összerakni egy áttekintő ábrát a feldolgozási folyamatról!</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./docs/images/processing-flow/processing-flow.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image proprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider only that cases, where the hue of objects on the images do not provide significant additional information in the aspect of symbol recognition.\n",
    "Our experiment suggest that the usage of grayscale images is sufficient.\n",
    "There are different methods for the grayscale convertion.\n",
    "The selection of them does not play key role in the further processing steps.\n",
    "\n",
    "We would like to reduce the effect of light condition changes.\n",
    "Some of the video capturing devices have capability to adapt to them.\n",
    "It helps to improve the image quality in the typical use case, but also means that any local intensity changes affect intensity changes globally.\n",
    "Fortunately, the estimation of motion vectors will eliminate this kind of noise automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion vector field estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sequential frames we can observe that some regions of the image are changing their positions.\n",
    "It does not necessarily match with the real position changes of the objects of the captured scene.\n",
    "Theoretically, it is possible to estimate the motion vector for any point of a frame.\n",
    "Therefore, it results a vector field on the domain of the image.\n",
    "\n",
    "The presented symbol recognition method based on the estimation of these motion vectors.\n",
    "The following paragraphs mention the reasons which makes the estimation task difficult.\n",
    "\n",
    "The *motion* is not a well-defined term in this consideration.\n",
    "It is an intuitive concept without a strict mathematical foundation.\n",
    "\n",
    "The estimation of a motion vector at a point requires the current frame and at least the previous one.\n",
    "On the analogy of interpolation methods, we could take into account more preceding frames.\n",
    "Expectedly, more frames are unable to cause significantly better classification accuracy.\n",
    "\n",
    "The frames are rasterized images.\n",
    "Smaller number of motion vectors is enough.\n",
    "\n",
    "We have to select the tracked parts of the image.\n",
    "All parts should have exactly the same shape and size.\n",
    "The segmentation of the image by a squared grid is appropriate.\n",
    "Moreover, it provides a more convenient calculation scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenCV library contains the implementation of an optical flow method of Lucas-Kanade [].\n",
    "We use an equidistant squared grid on the image.\n",
    "* The grid size is a free parameter of the method.\n",
    "* The window size is $50 \\times 50$.\n",
    "* We have choosed the maximal level of the image pyramid to 2.\n",
    "* The iterative search process termination criteria is $\\varepsilon = 0.03$ and the maximal count of iteration steps is 10.\n",
    "\n",
    "The implementation details of the algorithm and the tuning of proper parametrization is out of the scope of our current research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">TODO: Készíteni egy ábrát a rácsról!</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./docs/images/grid/grid.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat map calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated motion vectors describe the drawed symbol in time intervals with $\\Delta t$ lengths.\n",
    "For higher level view we have to aggregate the vector fields.\n",
    "A straightforward method of the aggregation is the usage of matrix which resembles to a heat map.\n",
    "\n",
    "Let consider only the measure of the motions which is available as the lengths of motion vectors.\n",
    "Let denote $l_i \\in \\mathbb{R}$ the length of a motion vector of the $i$-th frame.\n",
    "Let denote $h_i \\in \\mathbb{R}$ the *heat value* on the $i$-th frame.\n",
    "\n",
    "$$\n",
    "l_i, l_{i-1}, l_{i-2}, \\ldots, l_{i-k}\n",
    "$$\n",
    "We can use a $k+1$ sized convolution kernel.\n",
    "$C: \\mathbb{R}^{k+1} \\rightarrow \\mathbb{R}$\n",
    "\n",
    "We would like to find a proper aggregator function $f: \\mathbb{R}^2 \\rightarrow \\mathbb{R}$ as\n",
    "$$\n",
    "h_i = f(h_{i-1}, l_i).\n",
    "$$\n",
    "\n",
    "It requires a time window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">TODO: Készíteni képet egy hőtérképről!</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./docs/images/heatmap/heatmap.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal filter for Symbol Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of the drawed symbols can be differ significantly.\n",
    "The following approaches can be applied for solving this issue.\n",
    "\n",
    "* Usage of lower level primitives, for instance curves.\n",
    "* Define a temporal filter which is able to detect the begin and end of the symbol drawing process.\n",
    "\n",
    "We prefer to use the latter, because on successful time segment detection the symbol recognition task becomes the classical pattern recognition problem.\n",
    "\n",
    "By using the temporal filter, we obtain the snapshots of the heatmap where the symbols can be classified and it also makes possible to clear the heatmap after a symbol has drawn.\n",
    "We apply an experimental motion measure threshold (denoted by $\\mu$) and time limit (denoted by $\\tau$) for clearing the canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbol recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the ideal patterns in the resolution of the grid.\n",
    "These are the reference patterns.\n",
    "We calculate the sum of squared distances of pixel intensities.\n",
    "We select the reference image where this sum is minimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For checking the effectiveness of the proposed method, we define six symbols (Fig. 3).\n",
    "We have recorded six videos with at least 4 occurrences of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../program/')\n",
    "\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from arpt.frame_buffer import FrameBuffer\n",
    "from arpt import motion_field\n",
    "from arpt.video import Video\n",
    "\n",
    "symbol_names = [\n",
    "    'circle', 'square', 'triangle', 'nabla', 'plus', 'x'\n",
    "]\n",
    "\n",
    "measures = {}\n",
    "for symbol_name in symbol_names:\n",
    "    measures[symbol_name] = []\n",
    "    for suffix in ['.webm', '_test.mp4']:\n",
    "        frames = FrameBuffer()\n",
    "        video_path = f'sample_videos/{symbol_name}{suffix}'\n",
    "        print(video_path)\n",
    "        print(len(measures[symbol_name]))\n",
    "        with Video(video_path) as video:\n",
    "            while True:\n",
    "                frame = video.get_next_frame()\n",
    "                if frame is None:\n",
    "                    break\n",
    "                frames.push_frame(frame)\n",
    "                motion_vectors = motion_field.calc_optical_flow(frames[-1], frames[0], (18, 24))\n",
    "                lengths = motion_field.calc_lengths(motion_vectors)\n",
    "                measure = np.mean(np.mean(lengths))\n",
    "                measures[symbol_name].append(measure)\n",
    "        print(len(measures[symbol_name]))\n",
    "        print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(6, figsize=(12, 10), sharex=True)\n",
    "for i, symbol_name in enumerate(symbol_names):\n",
    "    axs[i].plot(measures[symbol_name])\n",
    "    axs[i].set_title(symbol_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid is 18 rows and 24 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_maps = {}\n",
    "\n",
    "for symbol_name in symbol_names:\n",
    "    heat_map = np.zeros((18, 24), dtype=np.float32)\n",
    "    for suffix in ['.webm', '_test.mp4']:\n",
    "        frames = FrameBuffer()\n",
    "        video_path = f'sample_videos/{symbol_name}{suffix}'\n",
    "        with Video(video_path) as video:\n",
    "            while True:\n",
    "                frame = video.get_next_frame()\n",
    "                if frame is None:\n",
    "                    break\n",
    "                frames.push_frame(frame)\n",
    "                motion_vectors = motion_field.calc_optical_flow(frames[-1], frames[0], (18, 24))\n",
    "                lengths = motion_field.calc_lengths(motion_vectors)\n",
    "                heat_map += lengths\n",
    "    heat_maps[symbol_name] = heat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol_name in symbol_names:\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    heat_map = heat_maps[symbol_name] / np.max(np.max(heat_maps[symbol_name]))\n",
    "    plt.imshow(heat_map, cmap='jet', interpolation='nearest')\n",
    "    plt.title(symbol_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MU = 2\n",
    "TAU = 40\n",
    "\n",
    "heat_maps = {}\n",
    "for symbol_name in symbol_names:\n",
    "    print(f'{symbol_name} ...')\n",
    "    heat_maps[symbol_name] = []\n",
    "    for suffix in ['.webm']:\n",
    "    #for suffix in ['.webm', '_test.mp4']:\n",
    "        frames = FrameBuffer()\n",
    "        is_first = True\n",
    "        video_path = f'sample_videos/{symbol_name}{suffix}'\n",
    "        with Video(video_path) as video:\n",
    "            heat_map = np.zeros((18, 24), dtype=np.float32)\n",
    "            n = 0\n",
    "            while True:\n",
    "                frame = video.get_next_frame()\n",
    "                if frame is None:\n",
    "                    heat_maps[symbol_name].append(heat_map)\n",
    "                    break\n",
    "                frames.push_frame(frame)\n",
    "                motion_vectors = motion_field.calc_optical_flow(frames[-1], frames[0], (18, 24))\n",
    "                lengths = motion_field.calc_lengths(motion_vectors)\n",
    "                measure = np.mean(np.mean(lengths))\n",
    "                if measure > MU:\n",
    "                    heat_map += lengths\n",
    "                    if n > TAU:\n",
    "                        if is_first is True:\n",
    "                            is_first = False\n",
    "                        else:\n",
    "                            heat_maps[symbol_name].append(heat_map)\n",
    "                        heat_map = np.zeros((18, 24), dtype=np.float32)\n",
    "                        n = 0\n",
    "                else:\n",
    "                    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol_name in symbol_names:\n",
    "    print(len(heat_maps[symbol_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual correction in _test\n",
    "del heat_maps['circle'][0]\n",
    "heat_maps['triangle'].append(heat_maps['triangle'][1] + heat_maps['triangle'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual correction\n",
    "del heat_maps['circle'][4]\n",
    "del heat_maps['nabla'][5]\n",
    "del heat_maps['nabla'][2]\n",
    "del heat_maps['x'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(6, 4, figsize=(14, 14), squeeze=False)\n",
    "for i, symbol_name in enumerate(symbol_names):\n",
    "    for k, heat_map in enumerate(heat_maps[symbol_name]):\n",
    "        axs[i, k].imshow(heat_map, cmap='jet', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_heat_maps = []\n",
    "for i, symbol_name in enumerate(symbol_names):\n",
    "    for k, heat_map in enumerate(heat_maps[symbol_name]):\n",
    "        indexed_heat_maps.append(heat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(hm1, hm2):\n",
    "    h1 = hm1 / np.max(np.max(hm1))\n",
    "    h2 = hm2 / np.max(np.max(hm2))\n",
    "    return np.linalg.norm(h1 - h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _test samples\n",
    "distances = np.empty((30, 30), dtype=float)\n",
    "for i1, h1 in enumerate(indexed_heat_maps):\n",
    "    for i2, h2 in enumerate(indexed_heat_maps):\n",
    "        distances[i1, i2] = calc_distance(h1, h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "distances = np.empty((24, 24), dtype=float)\n",
    "for i1, h1 in enumerate(indexed_heat_maps):\n",
    "    for i2, h2 in enumerate(indexed_heat_maps):\n",
    "        distances[i1, i2] = calc_distance(h1, h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "thresholded = np.where(distances < 3, distances, 10)\n",
    "plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(distances)\n",
    "plt.imshow(thresholded)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.max(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _test samples\n",
    "thresholded = np.where(distances < 3, 0, 1)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(thresholded)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _test samples\n",
    "for i1, h1 in enumerate(indexed_heat_maps):\n",
    "    min_distance = 88888888\n",
    "    for i2, h2 in enumerate(indexed_heat_maps):\n",
    "        if i1 != i2:\n",
    "            distance = calc_distance(h1, h2)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                guess = i2\n",
    "    print(f'{i1} ({i1 // 5}) -> {guess} ({guess // 5})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "for i1, h1 in enumerate(indexed_heat_maps):\n",
    "    min_distance = 88888888\n",
    "    for i2, h2 in enumerate(indexed_heat_maps):\n",
    "        if i1 != i2:\n",
    "            distance = calc_distance(h1, h2)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                guess = i2\n",
    "    print(f'{i1} ({i1 // 4}) -> {guess} ({guess // 4})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _test samples\n",
    "ref_indices = [0, 5, 10, 15, 20, 25]\n",
    "for i1, h1 in enumerate(indexed_heat_maps):\n",
    "    if i1 in ref_indices:\n",
    "        continue\n",
    "    min_distance = 88888888\n",
    "    for i2 in ref_indices:\n",
    "        if i1 != i2:\n",
    "            distance = calc_distance(h1, indexed_heat_maps[i2])\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                guess = i2\n",
    "    print(f'{i1} ({i1 // 5}) -> {guess} ({guess // 5})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, heat_map in enumerate(heat_maps['circle']):\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(heat_map, cmap='jet', interpolation='nearest')\n",
    "    plt.title(f'heat map {i}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "axs[0].imshow(heat_maps['circle'][2], cmap='jet', interpolation='nearest')\n",
    "axs[1].imshow(heat_maps['circle'][3], cmap='jet', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "axs[0].imshow(heat_maps['square'][2], cmap='jet', interpolation='nearest')\n",
    "axs[1].imshow(heat_maps['square'][3], cmap='jet', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "axs[0].imshow(heat_maps['triangle'][1], cmap='jet', interpolation='nearest')\n",
    "axs[1].imshow(heat_maps['triangle'][2], cmap='jet', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "axs[0].imshow(heat_maps['nabla'][1], cmap='jet', interpolation='nearest')\n",
    "axs[1].imshow(heat_maps['nabla'][3], cmap='jet', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "axs[0].imshow(heat_maps['plus'][2], cmap='jet', interpolation='nearest')\n",
    "axs[1].imshow(heat_maps['plus'][3], cmap='jet', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4), sharex=True)\n",
    "axs[0].imshow(heat_maps['x'][2], cmap='jet', interpolation='nearest')\n",
    "axs[1].imshow(heat_maps['x'][3], cmap='jet', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making dataset from datas, need more data!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.empty((0, 18*24), dtype=np.float32)\n",
    "y = np.empty((0, ), dtype=np.uint8)\n",
    "labels = symbol_names\n",
    "\n",
    "for gesture in heat_maps:\n",
    "    for heat_map in heat_maps[gesture]:\n",
    "        feature_vector = np.array(heat_map).flatten()\n",
    "        X = np.append(X, [feature_vector], axis=0)\n",
    "        y = np.append(y, [gesture], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "scaled_X = scaler.transform(X)\n",
    "\n",
    "print(len(y))\n",
    "print(np.mean(X))\n",
    "print(np.mean(scaled_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset to train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SIZE = 0.3\n",
    "SEED = 7\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = \\\n",
    "    train_test_split(scaled_X, y,\n",
    "                     test_size=TEST_SIZE,\n",
    "                      random_state=SEED)\n",
    "\n",
    "print(\"Training dataset size:\", len(Y_train))\n",
    "print(\"Testing dataset size:\", len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the dataset to estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier_args = dict(random_state=42,\n",
    "                       n_estimators=1400,\n",
    "                       max_depth=100)\n",
    "\n",
    "clf = RandomForestClassifier(**classifier_args)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making fonfusion matrix from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6), sharex=True)\n",
    "\n",
    "k=0\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(clf, X_test, Y_test,\n",
    "                                 display_labels=labels,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize,\n",
    "                                 ax=axs[k])\n",
    "    disp.ax_.set_title(title)\n",
    "    k+=1\n",
    "\n",
    "fig.savefig('test.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 seconds limit ..when the average motion is under a specified limit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbol selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we overview the different kind of noises.\n",
    "Light equalization\n",
    "\n",
    "movement noise reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an improved solution we could use Artificial Neural Networks for symbol detection.\n",
    "it is a further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">TODO: Rakaczki Csabát megkérdezni, hogy kell-e bele ilyesmi!</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 items"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
